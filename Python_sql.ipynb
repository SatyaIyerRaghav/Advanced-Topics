{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e74838",
   "metadata": {},
   "source": [
    "# Installing Library PYODBC for accessing SQL from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e6a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyodbc in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.32)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc319fc",
   "metadata": {},
   "source": [
    "# Step 1 Create 2 Tables in SQL SERVER and Add common data to both simultanoeusly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55fc29e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Inserted First Time in both Tables\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Replace these values with your SQL Server details\n",
    "server = 'LAPTOP-LD76VUNJ\\SQLEXPRESS'\n",
    "database = 'Demo'\n",
    "username = ''\n",
    "password = ''\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = 'D:\\Database_Python\\Sql_first21.xlsx'\n",
    "\n",
    "# Read the CSV file and get the headers\n",
    "csv_data = pd.read_excel(csv_file_path)\n",
    "\n",
    "table_name1 = \"Table3\"  # Replace with your desired table name\n",
    "table_name2 = \"Table4\"\n",
    "\n",
    "# Establish a connection to the SQL Server using SQLAlchemy\n",
    "engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server', pool_size=10, max_overflow=20)\n",
    "# Insert data into Table 1\n",
    "csv_data.to_sql(table_name1, con=engine, if_exists='append', index=False)\n",
    "    \n",
    "# Insert data into Table 2\n",
    "csv_data.to_sql(table_name2, con=engine, if_exists='append', index=False)\n",
    "print(\"Records Inserted First Time in both Tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a9607",
   "metadata": {},
   "source": [
    "## Step 2 -- Now Check for duplicates in table 2 with respect to Table 1 If have duplicates delete that common rows from table 1 and fetch non duplicated records from table1 and insert it into table 2.[This is the logic used]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced62ac",
   "metadata": {},
   "source": [
    "### NOTE: Here we kept the Commented code of Alter Table it is very important to run first if we get errors like Programming Error : Cannot convert nvarchar to float.Run once then again comment .You won't get errors again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2f41f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Press 1 to insert record Temp1 and checking for duplicates in Temp21\n",
      "Common rows found:\n",
      "common rows length: 20\n",
      "Deleted common rows.\n",
      "Table 1 has remaining rows length: 0\n",
      "No remaining rows in Temp1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Replace these values with your SQL Server details\n",
    "server = 'LAPTOP-LD76VUNJ\\SQLEXPRESS'\n",
    "database = 'Demo'\n",
    "username = ''\n",
    "password = ''\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path1 = 'D:\\Database_Python\\ChargesOUTPUT.xlsx'\n",
    "\n",
    "# Read the CSV file and get the headers\n",
    "csv_data = pd.read_excel(csv_file_path)\n",
    "\n",
    "table_name1 = \"Table3\"  # Replace with your desired table name\n",
    "table_name2 = \"Table4\"\n",
    "\n",
    "# checking for all Numeric and float columns and creating a list\n",
    "\n",
    "list_of_int_val=[]\n",
    "for i in csv_data:\n",
    "    if (csv_data[i].dtypes == 'int64' or csv_data[i].dtypes == 'float'):\n",
    "         list_of_int_val.append(i)            \n",
    "# print(list_of_int_val)     \n",
    "\n",
    "# fill all Nan values with 0\n",
    "csv_data = csv_data.fillna('0')\n",
    "# checking for isnull \n",
    "# print(csv_data.isnull().sum())\n",
    "\n",
    "# converting all \n",
    "for i in list_of_int_val:\n",
    "    csv_data[i] = csv_data[i].astype(str)\n",
    "print()  \n",
    "\n",
    "\n",
    "# Establish a connection to the SQL Server using SQLAlchemy\n",
    "engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server', pool_size=10, max_overflow=20)\n",
    "\n",
    "c = int(input(\"Press 1 to insert record Temp1 and checking for duplicates in Temp2\"))\n",
    "if c == 1:\n",
    "    try:\n",
    "#         convert_numeric_to_str = f'''\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [VISIT_NUMBER] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [CHARGES] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [OFFICE_KEY] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [ICD-10_CODE_3] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [ICD-10_DESCRIPTION_3] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [UNITS] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [XX] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [YY] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [TRANSACTION_CARRIER_NAME] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name1} ALTER COLUMN [CBO] nvarchar(1500)\n",
    " \n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [VISIT_NUMBER] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [CHARGES] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [OFFICE_KEY] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [ICD-10_CODE_3] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [ICD-10_DESCRIPTION_3] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [UNITS] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [XX] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [YY] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [TRANSACTION_CARRIER_NAME] nvarchar(1500)\n",
    "#                 ALTER TABLE {table_name2} ALTER COLUMN [CBO] nvarchar(1500)\n",
    "#         '''\n",
    "#         alter_rows = pd.read_sql_query(convert_numeric_to_str, engine)\n",
    "        \n",
    "#         print(\"Rows DataType Altered\")\n",
    "        \n",
    "        # Insert data into Table 1\n",
    "        csv_data.to_sql(table_name1, con=engine, if_exists='append', index=False)\n",
    "\n",
    "        # Check for common rows\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM {table_name1} t1\n",
    "        INNER JOIN {table_name2} t2\n",
    "        ON  t1.[SERVICE_DATE] = t2.[SERVICE_DATE] And\n",
    "        t1.[ENTRY_DATE] = t2.[ENTRY_DATE] and\n",
    "        t1.[VISIT_NUMBER] = t2.[VISIT_NUMBER] and\n",
    "        t1.[CPT_CODE] = t2.[CPT_CODE] and\n",
    "        t1.[GROUP_CODE] = t2.[GROUP_CODE] and\n",
    "        t1.[ENTRY_YEAR_AND_MONTH] = t2.[ENTRY_YEAR_AND_MONTH] and\n",
    "        t1.[CHARGES] = t2.[CHARGES] and\n",
    "        t1.[VOID]=t2.[VOID];\n",
    "        '''\n",
    "\n",
    "        common_rows = pd.read_sql_query(query, engine)\n",
    "\n",
    "        if not common_rows.empty:\n",
    "            print(\"Common rows found:\")\n",
    "#             print(common_rows)\n",
    "            print(\"common rows length:\",len(common_rows))\n",
    "            \n",
    "            # Execute an SQL query to delete common records from table1\n",
    "            delete_common_records_query = f'''\n",
    "            DELETE FROM {table_name1}\n",
    "            WHERE EXISTS (\n",
    "                SELECT 1\n",
    "                FROM {table_name2} t2\n",
    "                WHERE\n",
    "                    {table_name1}.[SERVICE_DATE] = t2.[SERVICE_DATE] And\n",
    "                    {table_name1}.[ENTRY_DATE] = t2.[ENTRY_DATE] and\n",
    "                    {table_name1}.[VISIT_NUMBER] = t2.[VISIT_NUMBER] and\n",
    "                    {table_name1}.[CPT_CODE] = t2.[CPT_CODE] and\n",
    "                    {table_name1}.[GROUP_CODE] = t2.[GROUP_CODE] and\n",
    "                    {table_name1}.[ENTRY_YEAR_AND_MONTH] = t2.[ENTRY_YEAR_AND_MONTH] and\n",
    "                    {table_name1}.[CHARGES] = t2.[CHARGES] and\n",
    "                    {table_name1}.[VOID]=t2.[VOID]\n",
    "                    )\n",
    "            '''\n",
    "\n",
    "            # Execute the DELETE query without trying to fetch results\n",
    "            engine.execute(delete_common_records_query)\n",
    "            print(\"Deleted common rows.\")\n",
    "\n",
    "            # Fetch remaining rows from Temp1\n",
    "            remaining_rows_query = f'''\n",
    "            SELECT * FROM {table_name1}\n",
    "            '''\n",
    "            remaining_rows = pd.read_sql_query(remaining_rows_query, engine)\n",
    "#             print(remaining_rows)\n",
    "            print(\"Table 1 has remaining rows length:\",len(remaining_rows))\n",
    "            \n",
    "            if not remaining_rows.empty:\n",
    "                print(\"Remaining rows in Temp1:\")\n",
    "              \n",
    "                remaining_rows.to_sql(table_name2, con=engine, if_exists='append', index=False)\n",
    "                # Fetch remaining rows from Temp2\n",
    "                remaining_rows_query2 = f'''\n",
    "                SELECT * FROM {table_name2}\n",
    "                '''\n",
    "                remaining_rows2 = pd.read_sql_query(remaining_rows_query2, engine)\n",
    "                print(\"Table 1 has remaining rows length:\",len(remaining_rows2))\n",
    "                print(\"Inserted remaining rows into Temp2.\")\n",
    "            else:\n",
    "                print(\"No remaining rows in Temp1.\")\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                print(\"No common rows.\")\n",
    "                csv_data.to_sql(table_name2, con=engine, if_exists='append', index=False)\n",
    "                print(\" Data Inserted into Table2\")\n",
    "                \n",
    "            except:\n",
    "#                 print(f\"Error converting column {col}: {str(e)}\")\n",
    "                  pass  \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24c7ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 to insert record Temp1 and checking for duplicates in Temp21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Replace these values with your SQL Server details\n",
    "server = 'LAPTOP-LD76VUNJ\\SQLEXPRESS'\n",
    "database = 'Demo'\n",
    "username = ''\n",
    "password = ''\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = 'D:\\Database_Python\\Sql_first21.xlsx'\n",
    "\n",
    "# Read the CSV file and get the headers\n",
    "csv_data = pd.read_excel(csv_file_path)\n",
    "\n",
    "table_name1 = \"Temp1\"  # Replace with your desired table name\n",
    "table_name2 = \"Temp2\"\n",
    "patient_details = \"Patient_Details\"\n",
    "# Establish a connection to the SQL Server using SQLAlchemy\n",
    "engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server', pool_size=10, max_overflow=20)\n",
    "\n",
    "c = int(input(\"Press 1 to insert record Temp1 and checking for duplicates in Temp2\"))\n",
    "if c == 1:\n",
    "    try:\n",
    " \n",
    "        # Check if the table exists\n",
    "        table_exists_query = f\"IF OBJECT_ID('{patient_details}', 'U') IS NOT NULL SELECT 1 ELSE SELECT 0\"\n",
    "        result = engine.execute(table_exists_query).scalar()\n",
    "\n",
    "        if result:\n",
    "            print(f\"Table '{patient_details}' exists\")\n",
    "            select_patient_data = f''' SELECT * FROM {patient_details} '''\n",
    "            fetch_patient_details = pd.read_sql_query(select_patient_data, engine)\n",
    "            \n",
    "            if not fetch_patient_details.empty:\n",
    "               # Check for common rows\n",
    "                    query = f'''\n",
    "                    SELECT *\n",
    "                    FROM {table_name1} t1\n",
    "                    INNER JOIN {patient_details} t2\n",
    "                    ON  t1.[PATIENT_NAME_FIRST_LAST] = t2.[PATIENT_NAME_FIRST_LAST];\n",
    "                   '''\n",
    "                    common_rows = pd.read_sql_query(query, engine)\n",
    "                    if not common_rows.empty:\n",
    "                        print(\"Common rows found:\")\n",
    "                        print(common_rows)\n",
    "                        print(\"common rows length:\",len(common_rows))\n",
    "                    else:\n",
    "                        print(\"No common Rows Found:\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"Table '{patient_details}' does not exist\")    \n",
    "            \n",
    "            create_patient_table_query = f'''CREATE TABLE {patient_details} \n",
    "                                                (\n",
    "                                                  Id INT IDENTITY(1,1) PRIMARY KEY,\n",
    "                                                  [PATIENT_NAME_(FIRST_LAST)] VARCHAR(MAX)\n",
    "                                                 );\n",
    "                                            '''\n",
    "            created_patient = pd.read_sql_query(create_patient_table_query, engine)        \n",
    "            insert_patient_data = f'''SELECT DISTINCT [PATIENT_NAME_(FIRST_LAST)] FROM {table_name1}'''\n",
    "            insert_patient_details = pd.read_sql_query(insert_patient_data, engine)\n",
    "            insert_patient_details.to_sql(patient_details, con=engine, if_exists='append', index=False)\n",
    "            print(\"Patient Details Table Created and Data Inserted Successfully\")\n",
    "                \n",
    "    except Exception as e:\n",
    "#             print(\"Error:\", str(e))\n",
    "            pass\n",
    "else:\n",
    "    print(\"Problem in table creation\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1224d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Details Table Created and Data Inserted Successfully\n"
     ]
    }
   ],
   "source": [
    "insert_patient_data = f'''SELECT DISTINCT [PATIENT_NAME_(FIRST_LAST)] FROM {table_name1}'''\n",
    "insert_patient_details = pd.read_sql_query(insert_patient_data, engine)\n",
    "insert_patient_details.to_sql(patient_details, con=engine, if_exists='append', index=False)\n",
    "print(\"Patient Details Table Created and Data Inserted Successfully\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff43cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
